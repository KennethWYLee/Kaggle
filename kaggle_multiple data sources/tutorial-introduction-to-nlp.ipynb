{"cells":[{"metadata":{},"cell_type":"markdown","source":"![Header_NLP_Basics_1200x639](https://raw.githubusercontent.com/satishgunjal/images/master/Header_NLP_Basics_1200x639.png)\n<sub><sup>Image source https://www.forbes.com/</sup></sub>\n\nWe generate tons of data every day. Our WhatsApp chats, phone calls, emails, SMS's contains unstructured data which is easy for us to understand but not so easy for machines. In fact around 80% of available data is in unstructured format and considering the growth of faceless apps like Chatbot, this is going to increase. Majority of this unstructured data is in text format. It's easy for humans to analyze and process the unstructured text/audio data but it takes lots of time and quality also varies. So there is need of an automated system which can do it, that's where Natural Language Processing (NLP) technique of Artificial Intelligent(AI) comes for rescue.\n\nSo where does NLP stands in the realm of AI.\n\n![NLP_Venn](https://raw.githubusercontent.com/satishgunjal/images/master/NLP_Venn.png)\n\n\nYou can see there is overlap of ML and NLP, because once we convert unstructured data to structured format we can use Ml statistical tools and algorithms to solve the problems.\n\n# What is NLP?\nIn short NLP is an AI technique used to do text analysis. For nerds out there here is more formal definition of NLP.\n\n**\"Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data.\"**\n\nSo whenever we have lots of text data to analyze we can use NLP. Apart from text analysis, NLP also used for variety of other tasks. Few important use cases of NLP are,\n* **Text Classification**: Using NLP we can classify given corpus of text into different groups based on label or keywords.\n* **Sentiment Analysis**: To identify the sentiment(positive or negative) from given text. Very useful in case of movie/product/services reviews.\n* **Relationship Extraction**: Can be used to retrieve important relationship data from text. e.g. relationship between place and person.\n* **Chatbots**: NLP is one of the core building block of Chatbot platforms like Google Dialogflow, Amazon Lex.\n* **Speech recognition**: NLP is used to simplify speech recognition and make it less time-consuming.\n* **Question and Answering**: Using NLP we can analyze given textual data and build a model which can answer user questions.\n* **Named Entity Recognition(NER)**: We can identify important information (entity) like date time, place, person etc from text using NLP.\n* **Optical Character Recognition**: Given an image representing printed text, determine the corresponding text."},{"metadata":{},"cell_type":"markdown","source":"# Understanding the Text Data\nLike any other machine learning problem, in case of NLP also we are going to build the pipelines to perform text analysis. Before we go in details about pipeline steps lets try to understand how our text data is formatted. Our input text data can be unstructured but every sentence is collection of words and every document is collection of sentences. Every text corpus at its core is just a collection words.\n\n![Text_Hierarchy_NLP](https://raw.githubusercontent.com/satishgunjal/images/master/Text_Hierarchy_NLP.png)\n\nWe can have text corpus of any kind of data, with one or more than one document. In case of email's we may have separate document for each email and in case of reviews we may have one single document with tab separated data for each review."},{"metadata":{},"cell_type":"markdown","source":"# NLP Workflow\nIrrespective of our text data format, steps that are used to solve NLP problems remains more or less same. Major  steps that we follow while solving the NLP problems are as below.\n\n\n![NLP_Workflow](https://raw.githubusercontent.com/satishgunjal/images/master/NLP_Workflow.png)\n\nIn the text preprocessing step we remove all the clutter and noise from the text. Then we perform the exploratory data analysis to understand the data. Based on our understanding from data analysis, we create new features in feature engineering step. Now once we have well formatted data with features, to create a ML model as per our requirement. In the last step we test our model and deploy it in production."},{"metadata":{},"cell_type":"markdown","source":"## Text Preprocessing\nText preprocessing is very important step in NLP workflow, without it, we can't analyze the text data. Below are the three major steps in text preprocessing.\n\n![NLP_Text_Preprocessing](https://raw.githubusercontent.com/satishgunjal/images/master/NLP_Text_Preprocessing.png)\n\n* **Noise Removal**: Any text which is not relevant to the context of the data and the task that we want to perform is considered as noise. Most common noise in text data is HTML tags, stop words, punctuations, white spaces and URL's. So in this step we remove all these noisy elements from text. Libraries such as spaCy and NLTK also has standard dictionary of some of these noisy elements. If required we can also build our own list.\n* **Text Normalization**: On higher level normalization is used to reduce the dimensions of the features so that machine learning models can efficiently process the data. Text data contains multiple representation of same word, For example – “play”, “player”, “played”, “plays” and “playing” are the different variations of the word – “play”. These variations are useful in case of speech but not much useful for text analysis. During text normalization we convert all the disparities of a word into their normalized form. In this step we perform tokenization, lemmatization, stemming and sentence segmentation.\n* **Object Standardization**: Text data often contains words or phrases which are not present in any standard dictionaries of spaCy or NLTK library. So we have to handle all such words with the help of custom code. In this step we fix the non-standard words with the help of regular expression and custom lookup table."},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis\nIn case of unstructured text data exploratory data analysis plays an extremely important role. In this step we visualize and explore data to generate insights. Based on our understanding we try to summarize the main characteristics in data for feature generation. \n\n![NLP_EDA](https://raw.githubusercontent.com/satishgunjal/images/master/NLP_EDA_750x500.png)"},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering\nIn this step we convert the preprocessed data into features for machine learning models to work on. We can use below techniques to extract features from text data.\n* **Syntactic Parsing**: We use dependency grammar and part of speech (POS) tags for syntactic analysis.\n* **Entity Extraction**: It is more advanced form of language processing, that is used to identify parameter values from input text.\nThese parameter values can be places, people, organizations..etc. This is very useful to pickup the important topics or key section from a text input.\n* **Statistical Features**: Using technique like Term Frequency-Inverse Document Frequency(TF-IDF) we can convert text data into numerical format. We can also use Word Count, Sentence Count, Punctuation Counts etc to create count/density based features.\n* **Word Embedding**: Word embedding technique are used to represent the word as a vector. Popular model like Word2Vec can be used to perform such task. These word vectors can be used as features in machine learning models.\n\n![NLP_Feature_Engineering](https://raw.githubusercontent.com/satishgunjal/images/master/NLP_Feature_Engineering.png)\n\n<sub><sup>Image source https://www.udemy.com/</sup></sub>"},{"metadata":{},"cell_type":"markdown","source":"## Model Building & Deployment\n* First step in model building is to have separate set of training and test data sets. This will make sure that our model will get tested on unknown data.\n* Choose an algorithm as per task in hand. For example if we are working on classification problem then we can choose from variety of classification algorithm like Logistic Regression, Support Vector Machine, Naïve Bayes etc.\n* Create pipeline which will feed the data to the model. Same pipeline then can be used to test real word data.\n* Once pipeline is built test it using training dataset and evaluate the model using test dataset.\n* We can use variety of metric to test the model score. Once we get satisfactory score then deploy the model in production."},{"metadata":{},"cell_type":"markdown","source":"# Libraries for NLP\n\n* [Scikit-learn](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)\n* [Natural Language Toolkit (NLTK)](https://www.nltk.org/)\n* [spaCy – Industrial-Strength Natural Language Processing.](https://spacy.io/)\n* [Gensim - Gensim is a Python library for topic modelling, document indexing and similarity retrieval with large corpora](https://pypi.org/project/gensim/)\n* [Stanford CoreNLP – NLP services and packages by Stanford NLP Group](https://stanfordnlp.github.io/CoreNLP/)\n* [TextBlob: Simplified Text Processing](https://textblob.readthedocs.io/en/dev/)"},{"metadata":{},"cell_type":"markdown","source":"# References\n* https://www.analyticsvidhya.com/blog/2017/01/ultimate-guide-to-understand-implement-natural-language-processing-codes-in-python/\n* https://medium.com/@suneelpatel.in/nlp-pipeline-building-an-nlp-pipeline-step-by-step-7f0576e11d08\n* https://towardsdatascience.com/build-and-compare-3-models-nlp-sentiment-prediction-67320979de61\n* https://towardsdatascience.com/nlp-text-preprocessing-a-practical-guide-and-template-d80874676e79\n* https://towardsdatascience.com/text-preprocessing-in-natural-language-processing-using-python-6113ff5decd8#:~:text=In%20NLP%2C%20text%20preprocessing%20is,Stop%20words%20removal"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}